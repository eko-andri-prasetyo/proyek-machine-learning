{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eko-andri-prasetyo/proyek-machine-learning/blob/main/%5BClustering%5D_Submission_Akhir_BMLP_Eko_Andri_Prasetyo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Penting**\n",
        "- Jangan mengubah atau menambahkan cell text yang sudah disediakan, Anda hanya perlu mengerjakan cell code yang sudah disediakan.\n",
        "- Pastikan seluruh kriteria memiliki output yang sesuai, karena jika tidak ada output dianggap tidak selesai.\n",
        "- Misal, Anda menggunakan df = df.dropna() silakan gunakan df.isnull().sum() sebagai tanda sudah berhasil. Silakan sesuaikan seluruh output dengan perintah yang sudah disediakan.\n",
        "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
        "- Pastikan Anda menggunakan variabel df dari awal sampai akhir dan tidak diperbolehkan mengganti nama variabel tersebut.\n",
        "- Hapus simbol pagar (#) pada kode yang bertipe komentar jika Anda menerapkan kriteria tambahan\n",
        "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan\n",
        "- Pastikan Anda mengerjakan sesuai section yang sudah diberikan tanpa mengubah judul atau header yang disediakan."
      ],
      "metadata": {
        "id": "0tvAKGat01Sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INFORMASI DATASET**\n",
        "\n",
        "Dataset ini menyajikan gambaran mendalam mengenai perilaku transaksi dan pola aktivitas keuangan, sehingga sangat ideal untuk eksplorasi **deteksi penipuan (fraud detection)** dan **identifikasi anomali**. Dataset ini mencakup **2.512 sampel data transaksi**, yang mencakup berbagai atribut transaksi, demografi nasabah, dan pola penggunaan.\n",
        "\n",
        "Setiap entri memberikan wawasan komprehensif terhadap perilaku transaksi, memungkinkan analisis untuk **keamanan finansial** dan pengembangan model prediktif.\n",
        "\n",
        "## Fitur Utama\n",
        "\n",
        "- **`TransactionID`**: Pengidentifikasi unik alfanumerik untuk setiap transaksi.  \n",
        "- **`AccountID`**: ID unik untuk setiap akun, dapat memiliki banyak transaksi.  \n",
        "- **`TransactionAmount`**: Nilai transaksi dalam mata uang, mulai dari pengeluaran kecil hingga pembelian besar.  \n",
        "- **`TransactionDate`**: Tanggal dan waktu transaksi terjadi.  \n",
        "- **`TransactionType`**: Tipe transaksi berupa `'Credit'` atau `'Debit'`.  \n",
        "- **`Location`**: Lokasi geografis transaksi (nama kota di Amerika Serikat).  \n",
        "- **`DeviceID`**: ID perangkat yang digunakan dalam transaksi.  \n",
        "- **`IP Address`**: Alamat IPv4 yang digunakan saat transaksi, dapat berubah untuk beberapa akun.  \n",
        "- **`MerchantID`**: ID unik merchant, menunjukkan merchant utama dan anomali transaksi.  \n",
        "- **`AccountBalance`**: Saldo akun setelah transaksi berlangsung.  \n",
        "- **`PreviousTransactionDate`**: Tanggal transaksi terakhir pada akun, berguna untuk menghitung frekuensi transaksi.  \n",
        "- **`Channel`**: Kanal transaksi seperti `Online`, `ATM`, atau `Branch`.  \n",
        "- **`CustomerAge`**: Usia pemilik akun.  \n",
        "- **`CustomerOccupation`**: Profesi pengguna seperti `Dokter`, `Insinyur`, `Mahasiswa`, atau `Pensiunan`.  \n",
        "- **`TransactionDuration`**: Lama waktu transaksi (dalam detik).  \n",
        "- **`LoginAttempts`**: Jumlah upaya login sebelum transaksiâ€”jumlah tinggi bisa mengindikasikan anomali.\n",
        "\n",
        "Tugas kamu adalah membuat model clustering yang selanjutnya akan digunakan untuk membuat model klasifikasi.\n"
      ],
      "metadata": {
        "id": "sKi5D9qVVJvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**\n",
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning. Semua library yang dibutuhkan harus **import** di **cell** ini, jika ada library yang dijalankan di cell lain maka **submission langsung ditolak**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **1. Import Library**\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "import joblib"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset**\n",
        "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook lalu mengecek informasi dataset sebelum nantinya dilakukan pembersihan. Hal-hal yang perlu dilakukan pada tahapan ini yaitu:\n",
        "1. **Memahami Struktur Data**\n",
        "   - Dataset harus mengambil referensi wajib digunakan (bisa dilihat [Disini](https://drive.google.com/drive/folders/1Zs7VmPZ-jNwsRlMKH65Ea-LApSwx6lKx?usp=drive_link))\n",
        "   - Melakukan loading dataset ke dalam notebook dan menampilkan 5 baris pertama dengan function `head`.\n",
        "   - Tinjau jumlah baris kolom dan jenis data dalam dataset dengan function `info`.  \n",
        "   - Menampilkan statistik deskriptif dataset dengan menjalankan `describe`.\n",
        "   - Pastikan **setiap function tersebut** memiliki **output pada setiap cell** code. Jika tidak **submission langsung ditolak**\n",
        "   "
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan code ini untuk melakukan load data secara otomatis tanpa harus download data tersebut secara manual:\n",
        "```python\n",
        "url='https://docs.google.com/spreadsheets/d/e/2PACX-1vTbg5WVW6W3c8SPNUGc3A3AL-AG32TPEQGpdzARfNICMsLFI0LQj0jporhsLCeVhkN5AoRsTkn08AYl/pub?gid=2020477971&single=true&output=csv'\n",
        "df = pd.read_csv(url)\n",
        "```"
      ],
      "metadata": {
        "id": "JgKXTwx2LMQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penting: pada kriteria pertama hindari penggunaan print() dan display() karena seluruh fungsi yang digunakan sudah memiliki standar output dan menghasilkan output yang diharapkan.\n",
        "\n",
        "Kriteria 1 akan ditolak ketika:\n",
        "- print(__.head())\n",
        "- display(___.head())\n",
        "dst\n",
        "\n",
        "Kriteria 1 akan diterima ketika Anda menggunakan fungsi yang diminta tanpa menambahkan deskripsi apapun."
      ],
      "metadata": {
        "id": "9d2RyUOuefWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **2. Memuat Dataset**\n",
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTbg5WVW6W3c8SPNUGc3A3AL-AG32TPEQGpdzARfNICMsLFI0LQj0jporhsLCeVhkN5AoRsTkn08AYl/pub?gid=2020477971&single=true&output=csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "-tfuxA86YztE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan 5 baris pertama dengan function head.\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tinjau jumlah baris kolom dan jenis data dalam dataset dengan info.\n",
        "df.info()"
      ],
      "metadata": {
        "id": "0MgRVyMLnR5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan statistik deskriptif dataset dengan menjalankan describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "hN9KsJPonVKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**\n",
        "\n",
        "**Apabila ingin menerapkan Advanced, pastikan seluruh visualisasi tidak ada yang overlap**"
      ],
      "metadata": {
        "id": "DNOEZk24uiXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan korelasi antar fitur (Opsional Skilled 1)\n",
        "plt.figure(figsize=(12, 8))\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Korelasi Antar Fitur Numerik')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DGAJlKExnYAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan histogram untuk semua kolom numerik (Opsional Skilled 1)\n",
        "numeric_df.hist(figsize=(15, 10), bins=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kcBn9v4Fn8FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ],
      "metadata": {
        "id": "k-S35baFuwaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi yang lebih informatif (Opsional Advanced 1)\n",
        "# Pairplot untuk melihat hubungan antar fitur numerik dengan warna berdasarkan fitur kategorikal\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pilih subset fitur numerik untuk visualisasi\n",
        "numeric_features = ['TransactionAmount', 'AccountBalance', 'CustomerAge', 'TransactionDuration', 'LoginAttempts']\n",
        "\n",
        "# Buat pairplot dengan hue berdasarkan Channel (contoh fitur kategorikal)\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.pairplot(df[numeric_features + ['Channel']].sample(1000), hue='Channel', palette='viridis', diag_kind='kde')\n",
        "plt.suptitle('Pairplot Fitur Numerik dengan Warna Berdasarkan Channel', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot untuk melihat distribusi TransactionAmount berdasarkan Occupation\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=df, x='CustomerOccupation', y='TransactionAmount')\n",
        "plt.title('Distribusi TransactionAmount Berdasarkan Occupation')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap korelasi dengan annotasi yang lebih jelas\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr_matrix = df.select_dtypes(include=[np.number]).corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
        "           square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Heatmap Korelasi Fitur Numerik (Segitiga Atas)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Countplot untuk fitur kategorikal dengan rotasi label\n",
        "categorical_features = ['TransactionType', 'Channel', 'CustomerOccupation']\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    value_counts = df[feature].value_counts()\n",
        "    sns.barplot(x=value_counts.index, y=value_counts.values, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribusi {feature}')\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "    axes[i].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot dengan fitur numerik penting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df, x='TransactionAmount', y='AccountBalance',\n",
        "               hue='TransactionType', size='CustomerAge', alpha=0.6)\n",
        "plt.title('TransactionAmount vs AccountBalance (Color: TransactionType, Size: Age)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GVIuT8VDokKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Pembersihan dan Pra Pemrosesan Data**\n",
        "\n",
        "Pada tahap ini, Anda akan melakukan **Pembersihan Dataset** untuk menjadikan dataset mudah diintepretasi dan bisa dilatih. Hal-hal yang wajib kamu lakukan yaitu:\n",
        "\n",
        "1. **Mengecek dataset** menggunakan isnull().sum() dan duplicated().sum().\n",
        "2. Melakukan feature scaling menggunakan `MinMaxScaler()` atau `StandardScalar()` untuk fitur numerik.\n",
        "3. Melakukan feature encoding menggunakan `LabelEncoder()` untuk fitur kategorikal.\n",
        "4. Melakukan drop pada kolom id.\n",
        "5. **Ketentuan Cell Code**\n",
        "   - Pastikan **setiap pemeriksaan tersebut** memiliki **output pada cell-nya**. Jika tidak **submission langsung ditolak**\n"
      ],
      "metadata": {
        "id": "cSemyzQHU0On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek dataset menggunakan isnull().sum()\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "dKeejtvxM6X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek dataset menggunakan duplicated().sum()\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "2RrBA92mpHBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan feature scaling menggunakan MinMaxScaler() atau StandardScalar() untuk fitur numerik.\n",
        "# Pastikan kamu menggunakan function head setelah melalukan scaling.\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df_scaled = df.copy()\n",
        "df_scaled[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "df_scaled.head()"
      ],
      "metadata": {
        "id": "G7WXozOgpJp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan drop pada kolom yang memiliki keterangan id dan IP Address\n",
        "id_cols = ['TransactionID', 'AccountID', 'DeviceID', 'IP Address', 'MerchantID']\n",
        "df_scaled = df_scaled.drop(columns=id_cols)"
      ],
      "metadata": {
        "id": "TGLR0NTwsMOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan feature encoding menggunakan LabelEncoder() untuk fitur kategorikal.\n",
        "# Pastikan kamu menggunakan function head setelah melalukan encoding.\n",
        "categorical_cols = df_scaled.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_scaled[col] = le.fit_transform(df_scaled[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "df_scaled.head()"
      ],
      "metadata": {
        "id": "6eycdNMQqx4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last checking gunakan columns.tolist() untuk checking seluruh fitur yang ada.\n",
        "# Perbaiki kode di bawah ini tanpa menambahkan atau mengurangi cell code ini.\n",
        "# ____.columns.tolist()\n",
        "df_scaled.columns.tolist()"
      ],
      "metadata": {
        "id": "u1EmlGmZCCAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Pembersihan dan Pra Pemrosesan Data [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**"
      ],
      "metadata": {
        "id": "qnbH2l_wv9l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menangani data yang hilang (bisa menggunakan dropna() atau metode imputasi fillna()).\n",
        "df_scaled = df_scaled.dropna()"
      ],
      "metadata": {
        "id": "-UoGhAUrsxIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus data duplikat menggunakan drop_duplicates().\n",
        "df_scaled = df_scaled.drop_duplicates()"
      ],
      "metadata": {
        "id": "WGt2XApTttSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Pembersihan dan Pra Pemrosesan Data [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ],
      "metadata": {
        "id": "H5RrswThwQrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan Handling Outlier Data berdasarkan jumlah outlier, apakah menggunakan metode drop atau mengisi nilai tersebut.\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# Identifikasi outlier menggunakan Z-score untuk fitur numerik\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "outlier_info = {}\n",
        "\n",
        "print(\"Deteksi Outlier menggunakan Z-score (threshold > 3):\")\n",
        "for col in numeric_cols:\n",
        "    z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
        "    outlier_count = np.sum(z_scores > 3)\n",
        "    outlier_percentage = (outlier_count / len(df[col].dropna())) * 100\n",
        "    outlier_info[col] = {'count': outlier_count, 'percentage': outlier_percentage}\n",
        "\n",
        "    print(f\"{col}: {outlier_count} outlier ({outlier_percentage:.2f}%)\")\n",
        "\n",
        "# Handle outlier berdasarkan persentase\n",
        "for col in numeric_cols:\n",
        "    if outlier_info[col]['percentage'] < 5:  # Jika outlier < 5%, drop\n",
        "        z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
        "        outlier_mask = z_scores > 3\n",
        "        df = df[~outlier_mask]\n",
        "        print(f\"Dropped {outlier_info[col]['count']} outliers from {col}\")\n",
        "    else:  # Jika outlier > 5%, cap dengan IQR method\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Cap the outliers\n",
        "        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
        "        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
        "        print(f\"Capped outliers in {col} using IQR method\")\n",
        "\n",
        "print(f\"Shape setelah handling outlier: {df.shape}\")"
      ],
      "metadata": {
        "id": "mvhfyYpat9Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan binning data berdasarkan kondisi rentang nilai pada fitur numerik,\n",
        "# lakukan pada satu sampai dua fitur numerik.\n",
        "# Silahkan lakukan encode hasil binning tersebut menggunakan LabelEncoder.\n",
        "# Pastikan kamu mengerjakan tahapan ini pada satu cell.\n",
        "# Binning untuk TransactionAmount\n",
        "transaction_bins = [0, 100, 500, 2000, 10000, float('inf')]\n",
        "transaction_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
        "df['TransactionAmount_Binned'] = pd.cut(df['TransactionAmount'], bins=transaction_bins, labels=transaction_labels, include_lowest=True)\n",
        "\n",
        "# Binning untuk CustomerAge\n",
        "age_bins = [0, 25, 35, 45, 55, 65, float('inf')]\n",
        "age_labels = ['Young', 'Young Adult', 'Middle Age', 'Senior', 'Elderly', 'Very Elderly']\n",
        "df['CustomerAge_Binned'] = pd.cut(df['CustomerAge'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
        "\n",
        "# Encode hasil binning menggunakan LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['TransactionAmount_Encoded'] = le.fit_transform(df['TransactionAmount_Binned'].astype(str))\n",
        "df['CustomerAge_Encoded'] = le.fit_transform(df['CustomerAge_Binned'].astype(str))\n",
        "\n",
        "# Drop kolom binning asli yang tidak terencode\n",
        "df = df.drop(['TransactionAmount_Binned', 'CustomerAge_Binned'], axis=1)\n",
        "\n",
        "print(\"Binning dan encoding selesai. 5 baris pertama:\")\n",
        "df[['TransactionAmount', 'TransactionAmount_Encoded', 'CustomerAge', 'CustomerAge_Encoded']].head()"
      ],
      "metadata": {
        "id": "QjcR-3G0u-GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Clustering**\n",
        "Pada tahap ini, Anda membangun model clustering dengan memilih algoritma yang sesuai untuk mengelompokkan data berdasarkan kesamaan.\n",
        "1. Pastikan Anda menggunakan dataframe yang sudah melalui processing sesuai dengan levelnya (Basic, Skilled, Advanced)\n",
        "2. Melakukan visualisasi Elbow Method untuk menentukan jumlah cluster terbaik menggunakan `KElbowVisualizer()`.\n",
        "3. Menggunakan algoritma K-Means Clustering dengan `sklearn.cluster.KMeans()`.\n",
        "4. Jalankan cell code `joblib.dump(model_kmeans, \"model_clustering.h5\")` untuk menyimpan model yang sudah dibuat."
      ],
      "metadata": {
        "id": "Fkd_QHXWMBDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gunakan describe untuk memastikan proses clustering menggunakan dataset hasil preprocessing\n",
        "# Lengkapi kode ini dengan mengubah nama DataFrame yang akan dilatih.\n",
        "# Kode harus digunakan dan dilarang menambahkan syntax lainnya pada cell ini.\n",
        "# ___.describe()\n",
        "df_scaled.describe()"
      ],
      "metadata": {
        "id": "hYHmRnb42A1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan visualisasi Elbow Method menggunakan KElbowVisualizer()\n",
        "plt.figure(figsize=(10, 6))\n",
        "model = KMeans(random_state=42)\n",
        "visualizer = KElbowVisualizer(model, k=(2, 10))\n",
        "visualizer.fit(df_scaled)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "hgYvwWOzM93L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan algoritma K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(df_scaled)\n",
        "df_scaled['Cluster'] = clusters"
      ],
      "metadata": {
        "id": "HvngRg-r4EcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan cell code ini untuk menyimpan model kamu."
      ],
      "metadata": {
        "id": "6aVHlHyU1Dcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model menggunakan joblib\n",
        "# import joblib\n",
        "# joblib.dump(___, \"model_clustering.h5\")\n",
        "import joblib\n",
        "joblib.dump(kmeans, \"model_clustering.h5\")"
      ],
      "metadata": {
        "id": "D7AvYmQnY_fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Membangun Model Clustering [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**"
      ],
      "metadata": {
        "id": "YDOD9eVMx3mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung dan menampilkan nilai Silhouette Score.\n",
        "silhouette_avg = silhouette_score(df_scaled.drop('Cluster', axis=1), clusters)\n",
        "print(f\"Silhouette Score: {silhouette_avg:.4f}\")"
      ],
      "metadata": {
        "id": "SELNsH5O4Oyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat visualisasi hasil clustering\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(df_scaled.drop('Cluster', axis=1))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
        "plt.title('Visualisasi Hasil Clustering (PCA)')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K4EbkaXg4QAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Membangun Model Clustering [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ],
      "metadata": {
        "id": "uloMRbnsyAbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangun model menggunakan PCA.\n",
        "# ___ =PCA(n_components=<x>)\n",
        "# ___ = ____.fit_transform(___)\n",
        "# Menyimpan data PCA sebagai Dataframe dengan nama PCA_<numbers>\n",
        "# <data_final> = pd.DataFrame(___, columns=['PCA1', 'PCA2', <sesuaikan dengan jumlah n>])\n",
        "# Pastikan kamu membangun model Kmeans baru dengan data yang sudah dimodifikasi melalui PCA.\n",
        "# ___ = KMeans(n_clusters=<x>)\n",
        "# ___.fit(<data_final>)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Gunakan elbow method untuk menentukan jumlah komponen PCA optimal\n",
        "pca = PCA()\n",
        "pca.fit(df_scaled.drop('Target', axis=1))\n",
        "\n",
        "# Plot variance explained ratio\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1),\n",
        "         np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance Explained')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance Ratio')\n",
        "plt.title('Cumulative Explained Variance by Principal Components')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Pilih n_components yang menjelaskan ~95% variance\n",
        "n_components = 8  # Disesuaikan berdasarkan plot di atas\n",
        "pca = PCA(n_components=n_components)\n",
        "pca_result = pca.fit_transform(df_scaled.drop('Target', axis=1))\n",
        "\n",
        "# Menyimpan data PCA sebagai Dataframe\n",
        "pca_columns = [f'PCA{i+1}' for i in range(n_components)]\n",
        "pca_df = pd.DataFrame(pca_result, columns=pca_columns)\n",
        "\n",
        "# Membangun model KMeans baru dengan data PCA\n",
        "kmeans_pca = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans_pca.fit(pca_df)\n",
        "\n",
        "# Tambahkan cluster labels ke dataframe PCA\n",
        "pca_df['Cluster_PCA'] = kmeans_pca.labels_\n",
        "\n",
        "print(f\"PCA dilakukan dengan {n_components} komponen utama\")\n",
        "print(f\"Variance explained: {np.sum(pca.explained_variance_ratio_):.4f}\")\n",
        "print(\"5 baris pertama data PCA:\")\n",
        "pca_df.head()"
      ],
      "metadata": {
        "id": "SgfOarXX4SD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model PCA sebagai perbandingan dengan menjalankan cell code ini joblib.dump(model,\"PCA_model_clustering.h5\")\n",
        "# Pastikan yang disimpan model yang sudah melalui .fit berdasarkan dataset yang sudah dilakukan PCA\n",
        "# joblib.dump(___, \"PCA_model_clustering.h5\")\n",
        "joblib.dump(kmeans_pca, \"PCA_model_clustering.h5\")\n",
        "\n",
        "# Visualisasi hasil clustering PCA (jika n_components >= 2)\n",
        "if n_components >= 2:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(pca_df['PCA1'], pca_df['PCA2'], c=kmeans_pca.labels_, cmap='viridis', alpha=0.6)\n",
        "    plt.xlabel('PCA Component 1')\n",
        "    plt.ylabel('PCA Component 2')\n",
        "    plt.title('Clustering dengan PCA (2 Komponen Utama)')\n",
        "    plt.colorbar(label='Cluster')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # Bandingkan dengan clustering original\n",
        "    plt.scatter(df_scaled.iloc[:, 0], df_scaled.iloc[:, 1], c=df_scaled['Target'], cmap='viridis', alpha=0.6)\n",
        "    plt.xlabel('Feature 1 (Original)')\n",
        "    plt.ylabel('Feature 2 (Original)')\n",
        "    plt.title('Clustering tanpa PCA')\n",
        "    plt.colorbar(label='Cluster')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Model PCA clustering berhasil disimpan sebagai 'PCA_model_clustering.h5'\")"
      ],
      "metadata": {
        "id": "uKvJy9Ky4VB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Interpretasi Cluster**"
      ],
      "metadata": {
        "id": "anlTI9Trb7F6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Interpretasi Hasil Clustering**\n",
        "1. **Contoh Interpretasi:**\n",
        "- **Cluster 1: (Nasabah Bertransaksi dan Pendapatan Besar)**:\n",
        "  - **Rata-rata (mean) Annual Income:** 0.953 (48,260)\n",
        "  - **Rata-rata (mean) Spending Score:** 0.8 (56.48)\n",
        "  - **Analisis:** Cluster ini mencakup pelanggan dengan pendapatan tahunan tinggi dan tingkat pengeluaran yang cukup tinggi. Pelanggan dalam cluster ini cenderung memiliki daya beli yang tinggi dan mereka lebih cenderung untuk membelanjakan sebagian besar pendapatan mereka. Sehingga rekomendasi pada kelompok nasabah ini adalah dengan menawarkan produk-produk investasi atau perbankan yang berkualitas tinggi.\n"
      ],
      "metadata": {
        "id": "JfgVMEBDS3KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan analisis deskriptif minimal mean, min dan max untuk fitur numerik.\n",
        "# Silakan menambahkan fungsi agregasi lainnya untuk experience lebih baik.\n",
        "# pastikan output menghasilkan agregasi dan groupby bersamaan dengan mean, min, dan max.\n",
        "cluster_analysis = df_scaled.groupby('Cluster').agg(['mean', 'min', 'max'])\n",
        "cluster_analysis"
      ],
      "metadata": {
        "id": "Qmpy4fmV64Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menjelaskan karakteristik tiap cluster berdasarkan rentangnya.\n",
        "1. **Cluster 1: (___)**:\n",
        "  - **Rata-rata (mean) <Fitur>:** <Sebelum inverse> <Setelah inverse>\n",
        "  - **Analisis:** Cluster ini ..."
      ],
      "metadata": {
        "id": "KrjMI_dG6tnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Mengeksport Data**\n",
        "\n",
        "1. Simpan nama kolom hasil clustering dengan nama `Target`.\n",
        "2. Simpan hasilnya ke dalam file CSV menggunakan function `to_csv()`."
      ],
      "metadata": {
        "id": "jaYP1fx5VgWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan nama kolom clustering sudah diubah menjadi Target\n",
        "df_scaled = df_scaled.rename(columns={'Cluster': 'Target'})"
      ],
      "metadata": {
        "id": "3FInN10U5S4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan Data\n",
        "# ___.to_csv('data_clustering.csv', index=False)\n",
        "df_scaled.to_csv('data_clustering.csv', index=False)"
      ],
      "metadata": {
        "id": "fkbg_o80aRSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Interpretasi Hasil Clustering [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**"
      ],
      "metadata": {
        "id": "rz1vFc2yzFPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inverse dataset ke rentang normal untuk numerikal\n",
        "# df[numerical_cols] = <nama_scaler>.inverse_transform(df[numerical_cols])\n",
        "# tampilkan dataset yang sudah di-inverse\n",
        "# ___.head()\n",
        "df_inverse = df_scaled.copy()\n",
        "df_inverse[numeric_cols] = scaler.inverse_transform(df_scaled[numeric_cols])\n",
        "df_inverse.head()"
      ],
      "metadata": {
        "id": "OMcRV15y_hH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inverse dataset yang sudah diencode ke kategori aslinya.\n",
        "# Lengkapi kode berikut jika ingin menerapkan kriteria ini (silakan hapus simbol pagar pada kode yang akan digunakan.)\n",
        "# for ___ in categorical_cols:\n",
        "#     ___ = encoders[col]\n",
        "#     df[col] = ___.inverse_transform(df_inverse[col].astype(int))\n",
        "# tampilkan dataset yang sudah di-inverse\n",
        "# ___.head()\n",
        "for col in categorical_cols:\n",
        "    le = label_encoders[col]\n",
        "    df_inverse[col] = le.inverse_transform(df_inverse[col].astype(int))\n",
        "\n",
        "df_inverse.head()"
      ],
      "metadata": {
        "id": "wzIddcB6XjrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan analisis deskriptif minimal mean, min dan max untuk fitur numerik dan mode untuk kategorikal seperti pada basic tetapi menggunakan data yang sudah diinverse.\n",
        "# pastikan output menghasilkan agregasi dan groupby bersamaan dengan mean, min, dan max kembali setelah melakukan inverse.\n",
        "cluster_analysis_inverse = df_inverse.groupby('Target').agg({\n",
        "    'TransactionAmount': ['mean', 'min', 'max'],\n",
        "    'AccountBalance': ['mean', 'min', 'max'],\n",
        "    'CustomerAge': ['mean', 'min', 'max']\n",
        "})\n",
        "cluster_analysis_inverse"
      ],
      "metadata": {
        "id": "omCabiXBTklU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menjelaskan karakteristik tiap cluster berdasarkan rentangnya setelah inverse.\n",
        "1. **Cluster 1: (___)**:\n",
        "  - **Rata-rata (mean) <Fitur>:** <Sebelum inverse> <Setelah inverse>\n",
        "  - **Analisis:** Cluster ini ..."
      ],
      "metadata": {
        "id": "WcaT8sxVzLs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Opsional) Interpretasi Hasil Clustering [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ],
      "metadata": {
        "id": "jSd6vZslzatv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengintegrasikan kembali data yang telah di-inverse dengan hasil cluster.\n",
        "# Gabungkan data inverse dengan hasil cluster\n",
        "df_final = df_inverse.copy()\n",
        "df_final['Cluster'] = clusters\n",
        "\n",
        "# Analisis karakteristik setiap cluster\n",
        "cluster_analysis = df_final.groupby('Cluster').agg({\n",
        "    'TransactionAmount': ['mean', 'min', 'max', 'count'],\n",
        "    'AccountBalance': ['mean', 'min', 'max'],\n",
        "    'CustomerAge': ['mean', 'min', 'max'],\n",
        "    'TransactionDuration': ['mean'],\n",
        "    'LoginAttempts': ['mean'],\n",
        "    'TransactionType': lambda x: x.mode()[0] if not x.mode().empty else 'N/A',\n",
        "    'Channel': lambda x: x.mode()[0] if not x.mode().empty else 'N/A',\n",
        "    'CustomerOccupation': lambda x: x.mode()[0] if not x.mode().empty else 'N/A'\n",
        "})\n",
        "\n",
        "# Tampilkan analisis cluster\n",
        "print(\"ANALISIS KARAKTERISTIK CLUSTER:\")\n",
        "print(\"=\" * 60)\n",
        "for cluster_id in sorted(df_final['Cluster'].unique()):\n",
        "    cluster_data = cluster_analysis.loc[cluster_id]\n",
        "    print(f\"\\nCLUSTER {cluster_id + 1}:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Jumlah data: {cluster_data[('TransactionAmount', 'count')]:.0f}\")\n",
        "    print(f\"Rata-rata TransactionAmount: ${cluster_data[('TransactionAmount', 'mean')]:.2f}\")\n",
        "    print(f\"Rata-rata AccountBalance: ${cluster_data[('AccountBalance', 'mean')]:.2f}\")\n",
        "    print(f\"Rata-rata CustomerAge: {cluster_data[('CustomerAge', 'mean')]:.1f} tahun\")\n",
        "    print(f\"TransactionType paling umum: {cluster_data[('TransactionType', '<lambda>')]}\")\n",
        "    print(f\"Channel paling umum: {cluster_data[('Channel', '<lambda>')]}\")\n",
        "    print(f\"Occupation paling umum: {cluster_data[('CustomerOccupation', '<lambda>')]}\")"
      ],
      "metadata": {
        "id": "4mGIyUZ2zRCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan Data\n",
        "# ___.to_csv('data_clustering_inverse.csv', index=False)\n",
        "df_inverse.to_csv('data_clustering_inverse.csv', index=False)"
      ],
      "metadata": {
        "id": "BEASz_Q__jms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of Code."
      ],
      "metadata": {
        "id": "sWOK6TDTL0eH"
      }
    }
  ]
}